{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UE5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kFSqkTCdWKMI"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "awjrpqy-6MaQ"
      },
      "source": [
        "Important: If you're running on a local machine, be sure to follow the [installation instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md). This notebook includes only what's necessary to run in Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p3UGXxUii5Ym"
      },
      "source": [
        "### Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hGL97-GXjSUw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d3e0ba8-244e-4537-98f0-da0c417aafcf"
      },
      "source": [
        "!pip install -U --pre tensorflow-gpu==\"2.*\"\n",
        "!pip install tf_slim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.*\n",
            "  Using cached https://files.pythonhosted.org/packages/b2/52/058b3372ace9d2184c1627133da6faf1964290a921a990dcd29b05e7075a/tensorflow_gpu-2.3.0rc1-cp36-cp36m-manylinux2010_x86_64.whl\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.*) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.*) (3.10.0)\n",
            "Collecting tensorflow-estimator<2.4.0,>=2.3.0-rc0\n",
            "  Using cached https://files.pythonhosted.org/packages/39/96/1bf989e9b36b331cc113dd393d0fa0b952f254aca2fbf8363ce28ee1cc03/tensorflow_estimator-2.3.0rc0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.*) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.*) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.*) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.*) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.*) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.*) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.*) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.*) (1.1.2)\n",
            "Collecting tensorboard<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.*) (1.30.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.*) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.*) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.*) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.*) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow-gpu==2.*) (47.3.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (1.6.0.post3)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (1.6.1)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (4.1.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.*) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 2.3.0rc0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 1.14.0\n",
            "    Uninstalling tensorflow-estimator-1.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.14.0\n",
            "  Found existing installation: tensorboard 1.14.0\n",
            "    Uninstalling tensorboard-1.14.0:\n",
            "      Successfully uninstalled tensorboard-1.14.0\n",
            "  Found existing installation: tensorflow-gpu 1.14.0\n",
            "    Uninstalling tensorflow-gpu-1.14.0:\n",
            "      Successfully uninstalled tensorflow-gpu-1.14.0\n",
            "Successfully installed tensorboard-2.2.2 tensorflow-estimator-2.3.0rc0 tensorflow-gpu-2.3.0rc1\n",
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbiySagCUZjN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "a16cafd7-7ab2-46f9-c969-916a55bf5df4"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n_ap_s9ajTHH"
      },
      "source": [
        "Make sure you have `pycocotools` installed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bg8ZyA47i3pY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "57211bc8-392a-4f64-a88c-89bd5b40e45e"
      },
      "source": [
        "!pip install pycocotools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (2.0.1)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (0.29.20)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (47.3.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-vsOL3QR6kqs"
      },
      "source": [
        "Get `tensorflow/models` or `cd` to parent directory of the repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ykA0c-om51s1",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O219m6yWAj9l"
      },
      "source": [
        "Compile protobufs and install the object_detection package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PY41vdYYNlXc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c833ee2f-a6bf-4b76-e599-657462041d98"
      },
      "source": [
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s62yJyQUcYbp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "3e5dcf1b-8585-402c-945a-1de5246e42b4"
      },
      "source": [
        "%%bash \n",
        "cd models/research\n",
        "pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/models/research\n",
            "Requirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.20)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.18.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->Matplotlib>=2.1->object-detection==0.1) (1.12.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1289819 sha256=606c68372c40d35cdd7ec5d9e4ce0781d34c4ec213515f23a714978d5a3a6450\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5jplloh2/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "  Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed object-detection-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LBdjK2G5ywuc"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hV4P5gyTWKMI",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython.display import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r5FNuiRPWKMN"
      },
      "source": [
        "Import the object detection module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4-IMl4b6BdGO",
        "colab": {}
      },
      "source": [
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RYPCiag2iz_q"
      },
      "source": [
        "Patches:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mF-YlMl8c_bM",
        "colab": {}
      },
      "source": [
        "# patch tf1 into `utils.ops`\n",
        "utils_ops.tf = tf.compat.v1\n",
        "\n",
        "# Patch the location of gfile\n",
        "tf.gfile = tf.io.gfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSx_eBJ_qhMr",
        "colab_type": "text"
      },
      "source": [
        "## Übungvorbereitung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BOd8RNBDLGM",
        "colab_type": "text"
      },
      "source": [
        "### Globale Variablen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63SMRHOdDSoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Urls\n",
        "DATEI_NAME_FullIJCNN2013=\"FullIJCNN2013.zip\"\n",
        "URL_DATEI_FullIJCNN2013='https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/FullIJCNN2013.zip'\n",
        "\n",
        "DATEI_NAME_TrainIJCNN2013=\"TrainIJCNN2013.zip\"\n",
        "URL_DATEI_TrainIJCNN2013='https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/TrainIJCNN2013.zip'\n",
        "\n",
        "DATEI_NAME_TestIJCNN2013=\"TestIJCNN2013.zip\"\n",
        "URL_DATEI_TestIJCNN2013='https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/TestIJCNN2013.zip'\n",
        "\n",
        "DATEI_NAME_GT_TEXT=\"gt.txt\"\n",
        "URL_DATEI_GT_TEXT='https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/gt.txt'\n",
        "\n",
        "# Paths\n",
        "DIR_Datasets='./datasets'\n",
        "\n",
        "DIR_NAME_Full='FullIJCNN2013'\n",
        "\n",
        "DIR_NAME_Train='TrainIJCNN2013'\n",
        "\n",
        "DIR_NAME_test='TestIJCNN2013Download'\n",
        "\n",
        "ReadME_DATEI='ReadMe.txt'\n",
        "\n",
        "PATH_GT_TRAIN=str(pathlib.Path(DIR_Datasets)/DIR_NAME_Train/'gt.txt')\n",
        "\n",
        "PATH_GT_FULL=str(pathlib.Path(DIR_Datasets)/DIR_NAME_Full/'gt.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-tKpd4IsFdh",
        "colab_type": "text"
      },
      "source": [
        "###  Datensatz herunterladen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPp5ExFa2unn",
        "colab_type": "text"
      },
      "source": [
        "#### FullIJCNN2013.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaCwr6tbzAcs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a41a65d9-76dd-46b4-a0cf-97dc5695a003"
      },
      "source": [
        "PATH_TO_DOWNLOADED_full= tf.keras.utils.get_file(\n",
        "    fname=DATEI_NAME_FullIJCNN2013,\n",
        "    origin=URL_DATEI_FullIJCNN2013,\n",
        "    cache_dir='.',\n",
        "    extract=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/FullIJCNN2013.zip\n",
            "1661870080/1661866983 [==============================] - 70s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_gCfrxf21rG",
        "colab_type": "text"
      },
      "source": [
        "#### TrainIJCNN2013.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-YQwmY02aJN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "06a1c17f-1c04-4a7a-b756-817ea2696156"
      },
      "source": [
        "PATH_TO_DOWNLOADED_train = tf.keras.utils.get_file(\n",
        "    fname=DATEI_NAME_TrainIJCNN2013,\n",
        "    origin=URL_DATEI_TrainIJCNN2013,\n",
        "    cache_dir='.',\n",
        "    extract=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/TrainIJCNN2013.zip\n",
            "1104183296/1104177081 [==============================] - 49s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvJY-M9x25xm",
        "colab_type": "text"
      },
      "source": [
        "#### TestIJCNN2013.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quhLQFRQ2ZTQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "3c40ca4b-aa8d-4003-cc36-12cb9832cb42"
      },
      "source": [
        "PATH_TO_DOWNLOADED_test = tf.keras.utils.get_file(\n",
        "    fname=DATEI_NAME_TestIJCNN2013,\n",
        "    origin=URL_DATEI_TestIJCNN2013,\n",
        "    cache_dir='.',\n",
        "    extract=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/TestIJCNN2013.zip\n",
            "555679744/555674823 [==============================] - 26s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAkEqIIr3sW_",
        "colab_type": "text"
      },
      "source": [
        "#### gt.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYPF11-Trysi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "e57907cb-abf1-4130-f503-fffb02d3c0b7"
      },
      "source": [
        "PATH_TO_DOWNLOADED_gt_text = tf.keras.utils.get_file(\n",
        "    fname=DATEI_NAME_GT_TEXT,\n",
        "    origin=URL_DATEI_GT_TEXT,\n",
        "    cache_dir='.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/gt.txt\n",
            "32768/24794 [=======================================] - 0s 4us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPB14SMqSA0e",
        "colab_type": "text"
      },
      "source": [
        "### Bildformat Konvertieren"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxWK31kCcYzY",
        "colab_type": "text"
      },
      "source": [
        "### Reconstruct File-System\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh8l788Ocsp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### del zip-files\n",
        "os.remove(PATH_TO_DOWNLOADED_full)\n",
        "os.remove(PATH_TO_DOWNLOADED_train)\n",
        "os.remove(PATH_TO_DOWNLOADED_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IokSZcZYddSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### del sub-directorys\n",
        "import shutil\n",
        "\n",
        "\n",
        "## delete sub-directory of 'FullIJCNN2013'\n",
        "p=pathlib.Path(DIR_Datasets)/DIR_NAME_Full\n",
        "dir_list1=[x for x in p.iterdir() if x.is_dir()]\n",
        "for sub_dir in dir_list1:\n",
        "  shutil.rmtree(sub_dir)\n",
        "\n",
        "## delete sub-directory of 'TrainIJCNN2013'\n",
        "p=pathlib.Path(DIR_Datasets)/DIR_NAME_Train\n",
        "dir_list1=[x for x in p.iterdir() if x.is_dir()]\n",
        "for sub_dir in dir_list1:\n",
        "  shutil.rmtree(sub_dir)\n",
        "\n",
        "## delete sub-directory of 'TrainIJCNN2013Download'\n",
        "p=pathlib.Path(DIR_Datasets)/DIR_NAME_test\n",
        "dir_list1=[x for x in p.iterdir() if x.is_dir()]\n",
        "for sub_dir in dir_list1:\n",
        "  shutil.rmtree(sub_dir)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5ZPf2gOSznv",
        "colab_type": "text"
      },
      "source": [
        "### PPM to JPEG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy8hawxhDe4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def change_image_format_batch(src_path, tar_path, fmt_in, fmt_out ):\n",
        "  '''\n",
        "  Bildkonvertierung für alle Bilder im Stammordner von Ausgangformat in Zielforamt\n",
        "  Args:\n",
        "    src_path : 'string',  Stammordner,aus dem wir Bilder einlesen \n",
        "    tar_path : 'string', Stammordner, wo wir Ergebnis ablegen\n",
        "    fmt_in  : 'string',  originale Bildformat\n",
        "    fmt_out : 'string',  erwartete Bildformat\n",
        "  '''\n",
        "  import glob,os\n",
        "  from PIL import Image\n",
        "\n",
        "  if os.path.exists(src_path)==False:\n",
        "    raise FileNotFoundError( 'No such file or directory:'+ src_path)\n",
        "  \n",
        "  img_dict=dict()\n",
        "  directorys=[ subpath for subpath in os.listdir(src_path) if   os.path.isdir( os.path.join(src_path,subpath) )   ]\n",
        "  #################################################\n",
        "  if len(directorys)==0:\n",
        "    imgPaths=glob.glob(os.path.join(src_path,'*.'+ fmt_in))\n",
        "    if os.path.exists(tar_path)==False:\n",
        "      os.makedirs(tar_path)\n",
        "    for imgPath in imgPaths:\n",
        "      im=Image.open(imgPath)\n",
        "      _,imgNamePPM=os.path.split(imgPath)\n",
        "      imgName,PPM=os.path.splitext(imgNamePPM)\n",
        "      im.save(os.path.join(tar_path,imgName+'.'+ fmt_out))\n",
        "    return\n",
        "\n",
        "\n",
        "  #################################################\n",
        "  for subdir in directorys:\n",
        "    img_dict[subdir]=glob.glob(os.path.join(src_path,subdir,'*.'+ fmt_in))\n",
        "  \n",
        "  if os.path.exists(tar_path)==False:\n",
        "    os.makedirs(tar_path)\n",
        "  # erstelle Ordner\n",
        "  for subdir,imgPaths in img_dict.items():\n",
        "    newLongdir=os.path.join(tar_path,subdir)\n",
        "    if os.path.exists(newLongdir)==False:\n",
        "      os.makedirs(newLongdir)\n",
        "    for imgPath in imgPaths:\n",
        "      im=Image.open(imgPath)\n",
        "      _,imgNamePPM=os.path.split(imgPath)\n",
        "      imgName,PPM=os.path.splitext(imgNamePPM)\n",
        "      im.save(os.path.join(tar_path,subdir,imgName+'.'+ fmt_out))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDcuSUGhD6IG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_path=pathlib.Path(DIR_Datasets)/DIR_NAME_Full\n",
        "tar_path=pathlib.Path(DIR_Datasets)/(DIR_NAME_Full+'_JPG')\n",
        "change_image_format_batch(\n",
        "    src_path=str(src_path),\n",
        "    tar_path=str(tar_path),\n",
        "    fmt_in='ppm',\n",
        "    fmt_out='jpg'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OPr3yv7tWMv",
        "colab_type": "text"
      },
      "source": [
        "### Prepare Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk39FF5Yt9KZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### read Label-Mapping-file,and convert to csv file\n",
        "import re\n",
        "Label_Mapping_CSV='label_mapping.csv'\n",
        "\n",
        "PATH_README=pathlib.Path(DIR_Datasets)/DIR_NAME_Full/ReadME_DATEI\n",
        "PATH_LABEL_CSV=pathlib.Path(DIR_Datasets)/DIR_NAME_Full/Label_Mapping_CSV\n",
        "\n",
        "# Text-Inhalt in Datei ReadMe.txt\n",
        "str_readme_txt=open(str(PATH_README),'r').read()\n",
        "str_list=re.findall('\\d+\\s=\\s.+',str_readme_txt,flags=re.MULTILINE)\n",
        "\n",
        "line_list=[  row.replace('=','; ') for row in str_list]\n",
        "\n",
        "with open(PATH_LABEL_CSV,'w',newline ='') as f:\n",
        "    print('id','name',sep=';',end='\\n',file=f)\n",
        "    f.write('\\n'.join(line_list))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKuyd1KjT69x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### writre pbtxt using csv\n",
        "import pandas as pd\n",
        "\n",
        "df_Label=pd.read_csv(\n",
        "    PATH_LABEL_CSV,\n",
        "    sep=';'\n",
        ")\n",
        "\n",
        "# offset\n",
        "\n",
        "df_Label['id']=df_Label['id']+1\n",
        "\n",
        "#PATH_PBTXT_DATEI=str(pathlib.Path('.')/'models/research/object_detection/data/gtsrb_label_map.pbtxt')\n",
        "PATH_PBTXT_DATEI=str(pathlib.Path('.')/'data/gtsrb_label_map.pbtxt')\n",
        "\n",
        "with open(PATH_PBTXT_DATEI,'w') as f:\n",
        "  for id,name in zip(df_Label['id'],df_Label['name']):\n",
        "    f.write('item {\\n')\n",
        "    f.write('  id: {}\\n'.format(id))\n",
        "    f.write('  name: \\'{}\\'\\n'.format(name))\n",
        "    f.write('}\\n')\n",
        "    f.write('\\n')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHUJkPSqt9OO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "ff7d85f9-f987-4e54-88e2-713a912988db"
      },
      "source": [
        "### extract information form gt.txt (including only training set)\n",
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv(\n",
        "    PATH_GT_FULL,\n",
        "    sep=';',\n",
        "    names=['filename','xmin','ymin','xmax','ymax','class'])\n",
        "df['filename']=df['filename'].str.replace('.ppm','.jpg')\n",
        "df['class']=df['class']+1\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000.jpg</td>\n",
              "      <td>774</td>\n",
              "      <td>411</td>\n",
              "      <td>815</td>\n",
              "      <td>446</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00001.jpg</td>\n",
              "      <td>983</td>\n",
              "      <td>388</td>\n",
              "      <td>1024</td>\n",
              "      <td>432</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00001.jpg</td>\n",
              "      <td>386</td>\n",
              "      <td>494</td>\n",
              "      <td>442</td>\n",
              "      <td>552</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00001.jpg</td>\n",
              "      <td>973</td>\n",
              "      <td>335</td>\n",
              "      <td>1031</td>\n",
              "      <td>390</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00002.jpg</td>\n",
              "      <td>892</td>\n",
              "      <td>476</td>\n",
              "      <td>1006</td>\n",
              "      <td>592</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208</th>\n",
              "      <td>00896.jpg</td>\n",
              "      <td>808</td>\n",
              "      <td>412</td>\n",
              "      <td>846</td>\n",
              "      <td>450</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209</th>\n",
              "      <td>00897.jpg</td>\n",
              "      <td>804</td>\n",
              "      <td>526</td>\n",
              "      <td>828</td>\n",
              "      <td>550</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1210</th>\n",
              "      <td>00898.jpg</td>\n",
              "      <td>323</td>\n",
              "      <td>504</td>\n",
              "      <td>355</td>\n",
              "      <td>536</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1211</th>\n",
              "      <td>00898.jpg</td>\n",
              "      <td>817</td>\n",
              "      <td>510</td>\n",
              "      <td>849</td>\n",
              "      <td>542</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1212</th>\n",
              "      <td>00899.jpg</td>\n",
              "      <td>864</td>\n",
              "      <td>484</td>\n",
              "      <td>921</td>\n",
              "      <td>534</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1213 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       filename  xmin  ymin  xmax  ymax  class\n",
              "0     00000.jpg   774   411   815   446     12\n",
              "1     00001.jpg   983   388  1024   432     41\n",
              "2     00001.jpg   386   494   442   552     39\n",
              "3     00001.jpg   973   335  1031   390     14\n",
              "4     00002.jpg   892   476  1006   592     40\n",
              "...         ...   ...   ...   ...   ...    ...\n",
              "1208  00896.jpg   808   412   846   450     16\n",
              "1209  00897.jpg   804   526   828   550     43\n",
              "1210  00898.jpg   323   504   355   536      5\n",
              "1211  00898.jpg   817   510   849   542      5\n",
              "1212  00899.jpg   864   484   921   534     25\n",
              "\n",
              "[1213 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFODEl_CySVv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "9888be5a-d651-4200-d9de-54667e572dbf"
      },
      "source": [
        "df_train=df.loc[df['filename']<='00599.jpg']\n",
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000.jpg</td>\n",
              "      <td>774</td>\n",
              "      <td>411</td>\n",
              "      <td>815</td>\n",
              "      <td>446</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00001.jpg</td>\n",
              "      <td>983</td>\n",
              "      <td>388</td>\n",
              "      <td>1024</td>\n",
              "      <td>432</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00001.jpg</td>\n",
              "      <td>386</td>\n",
              "      <td>494</td>\n",
              "      <td>442</td>\n",
              "      <td>552</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00001.jpg</td>\n",
              "      <td>973</td>\n",
              "      <td>335</td>\n",
              "      <td>1031</td>\n",
              "      <td>390</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00002.jpg</td>\n",
              "      <td>892</td>\n",
              "      <td>476</td>\n",
              "      <td>1006</td>\n",
              "      <td>592</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>00570.jpg</td>\n",
              "      <td>881</td>\n",
              "      <td>416</td>\n",
              "      <td>914</td>\n",
              "      <td>449</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>00571.jpg</td>\n",
              "      <td>1287</td>\n",
              "      <td>361</td>\n",
              "      <td>1308</td>\n",
              "      <td>384</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>00575.jpg</td>\n",
              "      <td>403</td>\n",
              "      <td>474</td>\n",
              "      <td>435</td>\n",
              "      <td>506</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>850</th>\n",
              "      <td>00593.jpg</td>\n",
              "      <td>584</td>\n",
              "      <td>510</td>\n",
              "      <td>608</td>\n",
              "      <td>534</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851</th>\n",
              "      <td>00599.jpg</td>\n",
              "      <td>700</td>\n",
              "      <td>454</td>\n",
              "      <td>722</td>\n",
              "      <td>476</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>852 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename  xmin  ymin  xmax  ymax  class\n",
              "0    00000.jpg   774   411   815   446     12\n",
              "1    00001.jpg   983   388  1024   432     41\n",
              "2    00001.jpg   386   494   442   552     39\n",
              "3    00001.jpg   973   335  1031   390     14\n",
              "4    00002.jpg   892   476  1006   592     40\n",
              "..         ...   ...   ...   ...   ...    ...\n",
              "847  00570.jpg   881   416   914   449     10\n",
              "848  00571.jpg  1287   361  1308   384     18\n",
              "849  00575.jpg   403   474   435   506     39\n",
              "850  00593.jpg   584   510   608   534     39\n",
              "851  00599.jpg   700   454   722   476     10\n",
              "\n",
              "[852 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GSA00f-yARB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "b0e1ad03-0225-4be9-cc90-249c4c2c4d81"
      },
      "source": [
        "df_test=df.loc[df['filename']>'00599.jpg']\n",
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>852</th>\n",
              "      <td>00601.jpg</td>\n",
              "      <td>82</td>\n",
              "      <td>450</td>\n",
              "      <td>145</td>\n",
              "      <td>508</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>853</th>\n",
              "      <td>00602.jpg</td>\n",
              "      <td>1268</td>\n",
              "      <td>555</td>\n",
              "      <td>1299</td>\n",
              "      <td>586</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>854</th>\n",
              "      <td>00602.jpg</td>\n",
              "      <td>443</td>\n",
              "      <td>543</td>\n",
              "      <td>474</td>\n",
              "      <td>574</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>855</th>\n",
              "      <td>00603.jpg</td>\n",
              "      <td>361</td>\n",
              "      <td>445</td>\n",
              "      <td>417</td>\n",
              "      <td>500</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>00604.jpg</td>\n",
              "      <td>365</td>\n",
              "      <td>482</td>\n",
              "      <td>437</td>\n",
              "      <td>546</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208</th>\n",
              "      <td>00896.jpg</td>\n",
              "      <td>808</td>\n",
              "      <td>412</td>\n",
              "      <td>846</td>\n",
              "      <td>450</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209</th>\n",
              "      <td>00897.jpg</td>\n",
              "      <td>804</td>\n",
              "      <td>526</td>\n",
              "      <td>828</td>\n",
              "      <td>550</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1210</th>\n",
              "      <td>00898.jpg</td>\n",
              "      <td>323</td>\n",
              "      <td>504</td>\n",
              "      <td>355</td>\n",
              "      <td>536</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1211</th>\n",
              "      <td>00898.jpg</td>\n",
              "      <td>817</td>\n",
              "      <td>510</td>\n",
              "      <td>849</td>\n",
              "      <td>542</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1212</th>\n",
              "      <td>00899.jpg</td>\n",
              "      <td>864</td>\n",
              "      <td>484</td>\n",
              "      <td>921</td>\n",
              "      <td>534</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>361 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       filename  xmin  ymin  xmax  ymax  class\n",
              "852   00601.jpg    82   450   145   508      8\n",
              "853   00602.jpg  1268   555  1299   586      9\n",
              "854   00602.jpg   443   543   474   574      9\n",
              "855   00603.jpg   361   445   417   500     11\n",
              "856   00604.jpg   365   482   437   546     31\n",
              "...         ...   ...   ...   ...   ...    ...\n",
              "1208  00896.jpg   808   412   846   450     16\n",
              "1209  00897.jpg   804   526   828   550     43\n",
              "1210  00898.jpg   323   504   355   536      5\n",
              "1211  00898.jpg   817   510   849   542      5\n",
              "1212  00899.jpg   864   484   921   534     25\n",
              "\n",
              "[361 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUKr1OeBBNZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "ae75c7c1-b79c-49c4-d4b1-f75cb633667c"
      },
      "source": [
        "df_merged_train=pd.merge(df_train, df_Label, how='left', left_on=['class'], right_on=['id'])\n",
        "df_merged_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "      <th>class</th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000.jpg</td>\n",
              "      <td>774</td>\n",
              "      <td>411</td>\n",
              "      <td>815</td>\n",
              "      <td>446</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>priority at next intersection (danger)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00001.jpg</td>\n",
              "      <td>983</td>\n",
              "      <td>388</td>\n",
              "      <td>1024</td>\n",
              "      <td>432</td>\n",
              "      <td>41</td>\n",
              "      <td>41</td>\n",
              "      <td>roundabout (mandatory)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00001.jpg</td>\n",
              "      <td>386</td>\n",
              "      <td>494</td>\n",
              "      <td>442</td>\n",
              "      <td>552</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>keep right (mandatory)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00001.jpg</td>\n",
              "      <td>973</td>\n",
              "      <td>335</td>\n",
              "      <td>1031</td>\n",
              "      <td>390</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>give way (other)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00002.jpg</td>\n",
              "      <td>892</td>\n",
              "      <td>476</td>\n",
              "      <td>1006</td>\n",
              "      <td>592</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>keep left (mandatory)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>00570.jpg</td>\n",
              "      <td>881</td>\n",
              "      <td>416</td>\n",
              "      <td>914</td>\n",
              "      <td>449</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>no overtaking (prohibitory)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>00571.jpg</td>\n",
              "      <td>1287</td>\n",
              "      <td>361</td>\n",
              "      <td>1308</td>\n",
              "      <td>384</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>no entry (other)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>00575.jpg</td>\n",
              "      <td>403</td>\n",
              "      <td>474</td>\n",
              "      <td>435</td>\n",
              "      <td>506</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>keep right (mandatory)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>850</th>\n",
              "      <td>00593.jpg</td>\n",
              "      <td>584</td>\n",
              "      <td>510</td>\n",
              "      <td>608</td>\n",
              "      <td>534</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>keep right (mandatory)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851</th>\n",
              "      <td>00599.jpg</td>\n",
              "      <td>700</td>\n",
              "      <td>454</td>\n",
              "      <td>722</td>\n",
              "      <td>476</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>no overtaking (prohibitory)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>852 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename  xmin  ymin  ...  class  id                                      name\n",
              "0    00000.jpg   774   411  ...     12  12    priority at next intersection (danger)\n",
              "1    00001.jpg   983   388  ...     41  41                    roundabout (mandatory)\n",
              "2    00001.jpg   386   494  ...     39  39                    keep right (mandatory)\n",
              "3    00001.jpg   973   335  ...     14  14                          give way (other)\n",
              "4    00002.jpg   892   476  ...     40  40                     keep left (mandatory)\n",
              "..         ...   ...   ...  ...    ...  ..                                       ...\n",
              "847  00570.jpg   881   416  ...     10  10               no overtaking (prohibitory)\n",
              "848  00571.jpg  1287   361  ...     18  18                          no entry (other)\n",
              "849  00575.jpg   403   474  ...     39  39                    keep right (mandatory)\n",
              "850  00593.jpg   584   510  ...     39  39                    keep right (mandatory)\n",
              "851  00599.jpg   700   454  ...     10  10               no overtaking (prohibitory)\n",
              "\n",
              "[852 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvzCdtRZCI4l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "b3ed5de9-b33d-478d-a81c-abdaa95deea3"
      },
      "source": [
        "df_merged_test=pd.merge(df_test, df_Label, how='left', left_on=['class'], right_on=['id'])\n",
        "df_merged_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "      <th>class</th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00601.jpg</td>\n",
              "      <td>82</td>\n",
              "      <td>450</td>\n",
              "      <td>145</td>\n",
              "      <td>508</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>speed limit 100 (prohibitory)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00602.jpg</td>\n",
              "      <td>1268</td>\n",
              "      <td>555</td>\n",
              "      <td>1299</td>\n",
              "      <td>586</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>speed limit 120 (prohibitory)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00602.jpg</td>\n",
              "      <td>443</td>\n",
              "      <td>543</td>\n",
              "      <td>474</td>\n",
              "      <td>574</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>speed limit 120 (prohibitory)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00603.jpg</td>\n",
              "      <td>361</td>\n",
              "      <td>445</td>\n",
              "      <td>417</td>\n",
              "      <td>500</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>no overtaking (trucks) (prohibitory)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00604.jpg</td>\n",
              "      <td>365</td>\n",
              "      <td>482</td>\n",
              "      <td>437</td>\n",
              "      <td>546</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>snow (danger)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>00896.jpg</td>\n",
              "      <td>808</td>\n",
              "      <td>412</td>\n",
              "      <td>846</td>\n",
              "      <td>450</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>no traffic both ways (prohibitory)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>00897.jpg</td>\n",
              "      <td>804</td>\n",
              "      <td>526</td>\n",
              "      <td>828</td>\n",
              "      <td>550</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>restriction ends (overtaking (trucks)) (other)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>00898.jpg</td>\n",
              "      <td>323</td>\n",
              "      <td>504</td>\n",
              "      <td>355</td>\n",
              "      <td>536</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>speed limit 70 (prohibitory)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>00898.jpg</td>\n",
              "      <td>817</td>\n",
              "      <td>510</td>\n",
              "      <td>849</td>\n",
              "      <td>542</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>speed limit 70 (prohibitory)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>00899.jpg</td>\n",
              "      <td>864</td>\n",
              "      <td>484</td>\n",
              "      <td>921</td>\n",
              "      <td>534</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>road narrows (danger)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>361 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename  xmin  ...  id                                              name\n",
              "0    00601.jpg    82  ...   8                     speed limit 100 (prohibitory)\n",
              "1    00602.jpg  1268  ...   9                     speed limit 120 (prohibitory)\n",
              "2    00602.jpg   443  ...   9                     speed limit 120 (prohibitory)\n",
              "3    00603.jpg   361  ...  11              no overtaking (trucks) (prohibitory)\n",
              "4    00604.jpg   365  ...  31                                     snow (danger)\n",
              "..         ...   ...  ...  ..                                               ...\n",
              "356  00896.jpg   808  ...  16                no traffic both ways (prohibitory)\n",
              "357  00897.jpg   804  ...  43    restriction ends (overtaking (trucks)) (other)\n",
              "358  00898.jpg   323  ...   5                      speed limit 70 (prohibitory)\n",
              "359  00898.jpg   817  ...   5                      speed limit 70 (prohibitory)\n",
              "360  00899.jpg   864  ...  25                             road narrows (danger)\n",
              "\n",
              "[361 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j-iMbbF_S6JJ"
      },
      "source": [
        "### JPEG to TFRecord"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i28X_xZC0-wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_one_tf_example_from_Img(filename,df_merged,image_dir):\n",
        "  from object_detection.utils import dataset_util\n",
        "  path_Image=str(pathlib.Path(image_dir)/filename) ## image path\n",
        "  image_string = open(path_Image, 'rb').read()\n",
        "  image_shape = tf.image.decode_jpeg(image_string).shape\n",
        "\n",
        "  height = image_shape[0] # Image height\n",
        "  width = image_shape[1] # Image width\n",
        "  filename = str.encode(filename) # Filename of the image. Empty if image is not from file\n",
        "  encoded_image_data = image_string # Encoded image bytes\n",
        "  image_format = b'jpeg' # b'jpeg' or b'png'\n",
        "\n",
        "  ## filename-specified sub-df\n",
        "  sub_df=df_merged.loc[df_merged['filename'].isin([filename.decode()])]\n",
        "\n",
        "  xmins = sub_df['xmin']/width # List of normalized left x coordinates in bounding box (1 per box)\n",
        "  xmaxs = sub_df['xmax']/width # List of normalized right x coordinates in bounding box\n",
        "             # (1 per box)\n",
        "  ymins = sub_df['ymin']/height # List of normalized top y coordinates in bounding box (1 per box)\n",
        "  ymaxs = sub_df['ymax']/height # List of normalized bottom y coordinates in bounding box\n",
        "             # (1 per box)\n",
        "  classes_text = sub_df['name'].str.encode(\"utf-8\") # List of string class name of bounding box (1 per box)\n",
        "  classes = sub_df['class'] # List of integer class id of bounding box (1 per box)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "      'image/height': dataset_util.int64_feature(height),\n",
        "      'image/width': dataset_util.int64_feature(width),\n",
        "      'image/filename': dataset_util.bytes_feature(filename),\n",
        "      'image/source_id': dataset_util.bytes_feature(filename),\n",
        "      'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
        "      'image/format': dataset_util.bytes_feature(image_format),\n",
        "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "  }))\n",
        "  return tf_example\n",
        "\n",
        "\n",
        "def create_gtsrb_tf_records(image_dir,output_dir,df_merged,record_file):\n",
        "  filenames=pd.unique(df_merged['filename'])\n",
        "  ###\n",
        "  if os.path.exists(output_dir)== False:\n",
        "    os.mkdir(output_dir)\n",
        "  path_record_file=str(pathlib.Path(output_dir)/record_file)\n",
        "  with tf.io.TFRecordWriter(path_record_file) as writer:\n",
        "    for filename in filenames:\n",
        "      tf_example=create_one_tf_example_from_Img(filename,df_merged,image_dir)\n",
        "      writer.write(tf_example.SerializeToString())\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTpjXcAnHf3K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea30e366-c347-4b08-9b5f-f4ce21e56fef"
      },
      "source": [
        "#####write TFRecord-file for training set\n",
        "record_file_train='train_images.tfrecords'\n",
        "#output_dir='models/research/object_detection/data'\n",
        "output_dir='data'\n",
        "\n",
        "\n",
        "image_dir=str(pathlib.Path(DIR_Datasets)/'FullIJCNN2013_JPG')\n",
        "\n",
        "create_gtsrb_tf_records(\n",
        "    image_dir=image_dir,\n",
        "    output_dir=output_dir,\n",
        "    df_merged=df_merged_train,\n",
        "    record_file=record_file_train\n",
        ")\n",
        "\n",
        "#####\n",
        "PATH_TRAIN_RECORD=str(pathlib.Path(output_dir)/record_file_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[0;34m(left, right, op, str_rep)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, op_str, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__rtruediv__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    547\u001b[0m     raise TypeError(\"unsupported operand type(s) for /: '{}' and 'Dimension', \"\n\u001b[0;32m--> 548\u001b[0;31m                     \"please use // instead\".format(type(other).__name__))\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'int' and 'Dimension', please use // instead",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-ce7a68c3c99b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdf_merged\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_merged_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mrecord_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecord_file_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-40a5eba13453>\u001b[0m in \u001b[0;36mcreate_gtsrb_tf_records\u001b[0;34m(image_dir, output_dir, df_merged, record_file)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_record_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0mtf_example\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_one_tf_example_from_Img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_merged\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m       \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-40a5eba13453>\u001b[0m in \u001b[0;36mcreate_one_tf_example_from_Img\u001b[0;34m(filename, df_merged, image_dir)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0msub_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_merged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mxmins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xmin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;31m# List of normalized left x coordinates in bounding box (1 per box)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mxmaxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xmax'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;31m# List of normalized right x coordinates in bounding box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m              \u001b[0;31m# (1 per box)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mlvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op, str_rep)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[0;34m(left, right, op, str_rep)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasked_arith_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_fill_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mmasked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# mask is only meaningful for x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: <class 'tensorflow.python.framework.tensor_shape.Dimension'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGdUbpLzflhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####write TFRecord-file for training set\n",
        "record_file_test='test_images.tfrecords'\n",
        "#output_dir='models/research/object_detection/data'\n",
        "output_dir='data'\n",
        "\n",
        "image_dir=str(pathlib.Path(DIR_Datasets)/'FullIJCNN2013_JPG')\n",
        "\n",
        "create_gtsrb_tf_records(\n",
        "    image_dir=image_dir,\n",
        "    output_dir=output_dir,\n",
        "    df_merged=df_merged_test,\n",
        "    record_file=record_file_test\n",
        ")\n",
        "#####\n",
        "PATH_TEST_RECORD=str(pathlib.Path(output_dir)/record_file_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utw37PXNow97",
        "colab_type": "text"
      },
      "source": [
        "### read TFRecord file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1JAPMheSUyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### print first 2 examples\n",
        "raw_dataset_train = tf.data.TFRecordDataset(PATH_TRAIN_RECORD)\n",
        "for raw_record in raw_dataset_train.take(2):\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(raw_record.numpy())\n",
        "  print(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpn39D_tTDrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### print first 2 examples\n",
        "raw_dataset_test = tf.data.TFRecordDataset(PATH_TEST_RECORD)\n",
        "for raw_record in raw_dataset_test.take(2):\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(raw_record.numpy())\n",
        "  print(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybp56aSKxlqp",
        "colab_type": "text"
      },
      "source": [
        "### get model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwWG-NA5Sarp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "e650ada7-7ba7-46c1-e3c8-7f6e34c2f163"
      },
      "source": [
        "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
        "  model_name='ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03'\n",
        "  model_file = model_name + '.tar.gz'\n",
        "  model_dir = tf.keras.utils.get_file(\n",
        "    fname=model_name, \n",
        "    origin=base_url + model_file,\n",
        "    cache_dir='.',\n",
        "    untar=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://download.tensorflow.org/models/object_detection/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz\n",
            "366952448/366947246 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EyTPDPx-4sz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c0c9bc82-0cd9-4059-d484-682e0f518f5b"
      },
      "source": [
        "%%bash\n",
        "cd data\n",
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ1FqSej8JHF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6ba5f195-2fa8-4859-b328-41fa38968405"
      },
      "source": [
        "%%bash\n",
        "\n",
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9_xOYXMpdXR",
        "colab_type": "text"
      },
      "source": [
        "### Config file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ8HlA8IxlZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8bdcc479-b8e5-4adf-97fc-537828435d24"
      },
      "source": [
        "%%bash\n",
        "cd models/research/\n",
        "python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-09 01:23:13.197592: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYeWJnPtmWhl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca7d4856-9222-4a56-c3ba-faf49a8850e4"
      },
      "source": [
        "%%bash\n",
        "export PYTHONPATH=$PYTHONPATH:/content/models\n",
        "\n",
        "cd models/research\n",
        "PIPELINE_CONFIG_PATH=\"/content/model/pipeline_ssd_resnet50_v1.config\"\n",
        "MODEL_DIR=\"/content/model/train\"\n",
        "NUM_TRAIN_STEPS=50000\n",
        "SAMPLE_1_OF_N_EVAL_EXAMPLES=1\n",
        "python object_detection/model_main.py \\\n",
        "    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \\\n",
        "    --model_dir=${MODEL_DIR} \\\n",
        "    --num_train_steps=${NUM_TRAIN_STEPS} \\\n",
        "    --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \\\n",
        "    --alsologtostderr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-09 10:16:10.015848: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0709 10:16:12.529564 140242792073088 model_lib.py:758] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 50000\n",
            "I0709 10:16:12.529834 140242792073088 config_util.py:552] Maybe overwriting train_steps: 50000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0709 10:16:12.529987 140242792073088 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0709 10:16:12.530175 140242792073088 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0709 10:16:12.530340 140242792073088 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0709 10:16:12.530560 140242792073088 model_lib.py:774] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0709 10:16:12.530714 140242792073088 model_lib.py:809] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/model/train', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0709 10:16:12.531296 140242792073088 estimator.py:191] Using config: {'_model_dir': '/content/model/train', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f8c7fc920d0>) includes params argument, but params are not passed to Estimator.\n",
            "W0709 10:16:12.532269 140242792073088 model_fn.py:629] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f8c7fc920d0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0709 10:16:12.533010 140242792073088 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0709 10:16:12.533279 140242792073088 training.py:645] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0709 10:16:12.533638 140242792073088 training.py:733] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0709 10:16:12.540358 140242792073088 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "2020-07-09 10:16:12.550002: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-09 10:16:12.553312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-09 10:16:12.554064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-07-09 10:16:12.554113: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-09 10:16:12.555901: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-09 10:16:12.557983: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-09 10:16:12.558436: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-09 10:16:12.560680: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-09 10:16:12.561719: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-09 10:16:12.566043: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-09 10:16:12.566238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-09 10:16:12.567082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-09 10:16:12.567866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "Traceback (most recent call last):\n",
            "  File \"object_detection/model_main.py\", line 108, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"object_detection/model_main.py\", line 104, in main\n",
            "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 505, in train_and_evaluate\n",
            "    return executor.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 646, in run\n",
            "    return self.run_local()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 747, in run_local\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 349, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1175, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1201, in _train_model_default\n",
            "    self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1037, in _get_features_and_labels_from_input_fn\n",
            "    self._call_input_fn(input_fn, mode))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1130, in _call_input_fn\n",
            "    return input_fn(**kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/inputs.py\", line 694, in _train_input_fn\n",
            "    params=params)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/inputs.py\", line 782, in train_input\n",
            "    model_config, is_training=True).preprocess\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/builders/model_builder.py\", line 984, in build\n",
            "    add_summaries)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/builders/model_builder.py\", line 360, in _build_ssd_model\n",
            "    _check_feature_extractor_exists(ssd_config.feature_extractor.type)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/builders/model_builder.py\", line 234, in _check_feature_extractor_exists\n",
            "    'Tensorflow'.format(feature_extractor_type))\n",
            "ValueError: ssd_resnet50_v1_fpn is not supported. See `model_builder.py` for features extractors compatible with different versions of Tensorflow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXury_JKOZsC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "448904ca-31b1-4a82-e51f-93f682063310"
      },
      "source": [
        "%%bash\n",
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80uzh6uvCVW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}